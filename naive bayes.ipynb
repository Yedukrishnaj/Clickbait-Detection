{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3056cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing different tools and libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import string as s\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8466685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gravitas: China moves 100 rocket launchers to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudan general declares state of emergency, \\nd...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India Deploys The Most Lethal Multi-Rocket Lau...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid cases rising in UK - what happens next? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newspaper Readership Then, Now and in the Future</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  clickbait  Unnamed: 2  \\\n",
       "0  Gravitas: China moves 100 rocket launchers to ...          0         NaN   \n",
       "1  Sudan general declares state of emergency, \\nd...          0         NaN   \n",
       "2  India Deploys The Most Lethal Multi-Rocket Lau...          0         NaN   \n",
       "3  Covid cases rising in UK - what happens next? ...          0         NaN   \n",
       "4   Newspaper Readership Then, Now and in the Future          0         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  \n",
       "0         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the Dataset\n",
    "cb_data= pd.read_csv('YouTube Videos - Sheet1.csv')\n",
    "cb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "266cc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gravitas: China moves 100 rocket launchers to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudan general declares state of emergency, \\nd...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India Deploys The Most Lethal Multi-Rocket Lau...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid cases rising in UK - what happens next? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newspaper Readership Then, Now and in the Future</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  clickbait  Unnamed: 2  \\\n",
       "0  Gravitas: China moves 100 rocket launchers to ...          0         NaN   \n",
       "1  Sudan general declares state of emergency, \\nd...          0         NaN   \n",
       "2  India Deploys The Most Lethal Multi-Rocket Lau...          0         NaN   \n",
       "3  Covid cases rising in UK - what happens next? ...          0         NaN   \n",
       "4   Newspaper Readership Then, Now and in the Future          0         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  \n",
       "0         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_dataset=pd.read_csv('YouTube Videos - Sheet1.csv')\n",
    "cb_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b96af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into Train and Test sets\n",
    "x=cb_data.headline\n",
    "y=cb_data.clickbait\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.25,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d456a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of elements in training set\n",
      "186\n",
      "No. of elements in testing set\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "#Analyzing Train and Test Data\n",
    "print(\"No. of elements in training set\")\n",
    "print(train_x.size)\n",
    "print(\"No. of elements in testing set\")\n",
    "print(test_x.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096a0d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64         Rare Moments in Sports That Shocked The World\n",
       "5      Pelosi is not just a tyrant, she is a hypocrit...\n",
       "85     Katrina and Vicky Kaushal- wedding and a divorce \n",
       "2      India Deploys The Most Lethal Multi-Rocket Lau...\n",
       "234                     WoW Alliance Is Officially Dead.\n",
       "144                    Ugliest Design Mistakes Ever Made\n",
       "109    FIFA 22 | NEW CONFIRMED TRANSFERS & RUMOURS SU...\n",
       "113                       10 Rarest Cars From The Future\n",
       "127    Unusual Kids Born with Unbelievable Medical Co...\n",
       "169    Unexplained Mysteries That NEED Some Serious E...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38228330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64     0\n",
       "5      0\n",
       "85     1\n",
       "2      0\n",
       "234    1\n",
       "144    0\n",
       "109    1\n",
       "113    0\n",
       "127    1\n",
       "169    0\n",
       "Name: clickbait, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7349f6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186                          Best Intro ever - office US\n",
       "90     Mumbai Monsoon: Truth of 'car sinking' viral v...\n",
       "166      RICH People Who Turned Themselves into PLASTIC!\n",
       "225                     WoW is Starting to Show its Age!\n",
       "91       Former detective says he knows who killed Tupac\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b041e2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186    0\n",
       "90     0\n",
       "166    0\n",
       "225    0\n",
       "91     1\n",
       "Name: clickbait, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6d6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of Data\n",
    "def tokenization(text):\n",
    "    lst=text.split()\n",
    "    return lst\n",
    "train_x=train_x.apply(tokenization)\n",
    "test_x=test_x.apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648fc422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to lowercase\n",
    "def lowercasing(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        i=i.lower()\n",
    "        new_lst.append(i)\n",
    "    return new_lst\n",
    "train_x=train_x.apply(lowercasing)\n",
    "test_x=test_x.apply(lowercasing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12b2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation\n",
    "def remove_punctuations(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        for j in s.punctuation:\n",
    "            i=i.replace(j,'')\n",
    "        new_lst.append(i)\n",
    "    return new_lst\n",
    "train_x=train_x.apply(remove_punctuations)\n",
    "test_x=test_x.apply(remove_punctuations)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43adcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Numbers\n",
    "def remove_numbers(lst):\n",
    "    nodig_lst=[]\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        for j in s.digits:    \n",
    "            i=i.replace(j,'')\n",
    "        nodig_lst.append(i)\n",
    "    for i in nodig_lst:\n",
    "        if i!='':\n",
    "            new_lst.append(i)\n",
    "    return new_lst\n",
    "train_x=train_x.apply(remove_numbers)\n",
    "test_x=test_x.apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4816b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Removing Stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da0526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\YEDU\n",
      "[nltk_data]     KJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601ad09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stopwords of English language \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All stopwords of English language \")\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78ac1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lst):\n",
    "    stop=stopwords.words('english')\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        if i not in stop:\n",
    "            new_lst.append(i)\n",
    "    return new_lst\n",
    "\n",
    "train_x=train_x.apply(remove_stopwords)\n",
    "test_x=test_x.apply(remove_stopwords)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b8490a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing extra spaces\n",
    "def remove_spaces(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        i=i.strip()\n",
    "        new_lst.append(i)\n",
    "    return new_lst\n",
    "train_x=train_x.apply(remove_spaces)\n",
    "test_x=test_x.apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919115a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64               [rare, moments, sports, shocked, world]\n",
       "5               [pelosi, tyrant, hypocrite, rep, massie]\n",
       "85           [katrina, vicky, kaushal, wedding, divorce]\n",
       "2      [india, deploys, lethal, multirocket, launcher...\n",
       "234                    [wow, alliance, officially, dead]\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyzing data after preprocessing\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "344c6e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186                      [best, intro, ever, office, us]\n",
       "90     [mumbai, monsoon, truth, car, sinking, viral, ...\n",
       "166                      [rich, people, turned, plastic]\n",
       "225                           [wow, starting, show, age]\n",
       "91       [former, detective, says, knows, killed, tupac]\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4c5a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\YEDU\n",
      "[nltk_data]     KJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a520cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "def lemmatzation(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        i=lemmatizer.lemmatize(i)\n",
    "        new_lst.append(i)\n",
    "    return new_lst\n",
    "train_x=train_x.apply(lemmatzation)\n",
    "test_x=test_x.apply(lemmatzation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cce1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x.apply(lambda x: ''.join(i+' ' for i in x))\n",
    "test_x=test_x.apply(lambda x: ''.join(i+' ' for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccbfbacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rare': 1,\n",
       " 'moment': 1,\n",
       " 'sport': 1,\n",
       " 'shocked': 1,\n",
       " 'world': 3,\n",
       " 'pelosi': 1,\n",
       " 'tyrant': 1,\n",
       " 'hypocrite': 1,\n",
       " 'rep': 1,\n",
       " 'massie': 1,\n",
       " 'katrina': 1,\n",
       " 'vicky': 1,\n",
       " 'kaushal': 1,\n",
       " 'wedding': 1,\n",
       " 'divorce': 1,\n",
       " 'india': 1,\n",
       " 'deploys': 1,\n",
       " 'lethal': 1,\n",
       " 'multirocket': 1,\n",
       " 'launcher': 1,\n",
       " 'lac': 1,\n",
       " 'amid': 1,\n",
       " 'tension': 1,\n",
       " 'china': 1,\n",
       " 'english': 1,\n",
       " 'news': 1,\n",
       " 'wow': 1,\n",
       " 'alliance': 1,\n",
       " 'officially': 1,\n",
       " 'dead': 1,\n",
       " 'ugliest': 1,\n",
       " 'design': 1,\n",
       " 'mistake': 1,\n",
       " 'ever': 1,\n",
       " 'made': 1,\n",
       " 'fifa': 1,\n",
       " 'new': 1,\n",
       " 'confirmed': 1,\n",
       " 'transfer': 1,\n",
       " 'rumour': 1,\n",
       " 'summer': 1,\n",
       " 'üò±‚úÖ': 1,\n",
       " 'w': 1,\n",
       " 'sterling': 1,\n",
       " 'ronaldo': 1,\n",
       " 'messi': 1,\n",
       " 'tottenham': 1,\n",
       " 'rarest': 2,\n",
       " 'car': 1,\n",
       " 'future': 1,\n",
       " 'unusual': 1,\n",
       " 'kid': 1,\n",
       " 'born': 1,\n",
       " 'unbelievable': 1,\n",
       " 'medical': 1,\n",
       " 'condition': 1,\n",
       " 'unexplained': 1,\n",
       " 'mystery': 1,\n",
       " 'need': 1,\n",
       " 'serious': 1,\n",
       " 'explaining': 1,\n",
       " 'shocking': 1,\n",
       " 'shark': 1,\n",
       " 'attack': 1,\n",
       " 'caught': 3,\n",
       " 'camera': 3,\n",
       " 'top': 1,\n",
       " 'santa': 1,\n",
       " 'claus': 1,\n",
       " 'spotted': 1,\n",
       " 'real': 1,\n",
       " 'life': 1,\n",
       " 'scary': 1,\n",
       " 'fishing': 1,\n",
       " 'video': 1,\n",
       " 'dangerous': 1,\n",
       " 'bug': 1,\n",
       " 'amazing': 1,\n",
       " 'abandoned': 1,\n",
       " 'vehicle': 1,\n",
       " 'animal': 1,\n",
       " 'planet': 1,\n",
       " 'brian': 1,\n",
       " 'kilmeade': 1,\n",
       " 'san': 1,\n",
       " 'franciscos': 1,\n",
       " 'looting': 1,\n",
       " 'free': 1,\n",
       " 'control': 1,\n",
       " 'tupac': 1,\n",
       " 'say': 1,\n",
       " 'pulled': 1,\n",
       " 'triggered': 1,\n",
       " '–ø—Ä–æ—â–∞–Ω–∏–µ': 1,\n",
       " '—Å': 1,\n",
       " '–∞—Ä—Ç–∞—Å–æ–º': 1,\n",
       " '–Ω–æ–≤—ã–π': 1,\n",
       " '—Å–∏–Ω–µ–º–∞—Ç–∏–∫': 1,\n",
       " 'shadowlands': 1,\n",
       " '–∫–æ–Ω–µ—Ü': 1,\n",
       " '–≤–µ—á–Ω–æ—Å—Ç–∏': 1,\n",
       " 'famous': 1,\n",
       " 'funny': 1,\n",
       " 'commercial': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist={}\n",
    "for i in train_x.head(20):\n",
    "    x=i.split()\n",
    "    for j in x:\n",
    "        if j not in freq_dist.keys():\n",
    "            freq_dist[j]=1\n",
    "        else:\n",
    "            freq_dist[j]+=1\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49167690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF (Term frequency-Inverse Data Frequency)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "train_1=tfidf.fit_transform(train_x)\n",
    "test_1=tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72921803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features extracted\n",
      "687\n",
      "\n",
      "The 100 features extracted from TF-IDF \n",
      "['abandoned', 'abnormally', 'according', 'actor', 'actress', 'actually', 'air', 'aj', 'al', 'alive', 'alliance', 'always', 'amazing', 'amazon', 'amid', 'anchor', 'anduin', 'angel', 'animal', 'animated', 'annoying', 'anthony', 'anushka', 'archaeologist', 'arena', 'arrested', 'arrow', 'artist', 'ascension', 'asmongold', 'aspect', 'assaulting', 'astroworld', 'attack', 'attends', 'attention', 'audio', 'aviv', 'away', 'bad', 'bald', 'balloon', 'barcelona', 'barely', 'beach', 'beautiful', 'becerra', 'becky', 'believe', 'bgt', 'biggest', 'biggie', 'blizzard', 'bobkata', 'body', 'bollywood', 'border', 'born', 'boss', 'break', 'breakdown', 'brian', 'broadcast', 'bryant', 'bug', 'build', 'burial', 'burning', 'buzzer', 'call', 'camera', 'can', 'cant', 'car', 'carell', 'carpenter', 'cartoon', 'cat', 'catch', 'caught', 'cctv', 'celebrity', 'challenge', 'chapter', 'cheating', 'check', 'chef', 'chicken', 'china', 'cinematic', 'city', 'clapper', 'clases', 'classic', 'classless', 'claus', 'clip', 'close', 'coin', 'color']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features extracted\")\n",
    "print(len(tfidf.get_feature_names()))\n",
    "print()\n",
    "print(\"The 100 features extracted from TF-IDF \")\n",
    "print(tfidf.get_feature_names()[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9805b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set (186, 687)\n",
      "Shape of test set (63, 687)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train set\",train_1.shape)\n",
    "print(\"Shape of test set\",test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60eb8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr=train_1.toarray()\n",
    "test_arr=test_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83355dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Naive Bayes Classifier\n",
    "NB_MN=MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455d6f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 20 actual labels:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "first 20 predicted labels:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "NB_MN.fit(train_arr,train_y)\n",
    "pred=NB_MN.predict(test_arr)\n",
    "print('first 20 actual labels: ',test_y.tolist()[:20])\n",
    "print('first 20 predicted labels: ',pred.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d0e7b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model\n",
      "0.4\n",
      "Accuracy of the model\n",
      "0.7142857142857143\n",
      "Accuracy of the model in percentage\n",
      "71.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Result\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1 score of the model\")\n",
    "print(f1_score(test_y,pred))\n",
    "print(\"Accuracy of the model\")\n",
    "print(accuracy_score(test_y,pred))\n",
    "print(\"Accuracy of the model in percentage\")\n",
    "print(accuracy_score(test_y,pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e208ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[39  3]\n",
      " [15  6]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        42\n",
      "           1       0.67      0.29      0.40        21\n",
      "\n",
      "    accuracy                           0.71        63\n",
      "   macro avg       0.69      0.61      0.61        63\n",
      "weighted avg       0.70      0.71      0.68        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y,pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_y,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81c6378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_x=cb_dataset.headline\n",
    "test1_y=cb_dataset.clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4efa41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of elements in testing set\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"No. of elements in testing set\")\n",
    "print(test1_x.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f79adb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26171    x e e n  c h r n  c n v e r  r r e e  r n  f c...\n",
       "16224      h r n g  h  h  n g e r  f u  f c u l  e b e r  \n",
       "27534         f u √ü b l l b u n e l g  ‚Äì  c h  r u n u p  \n",
       "27304                       c  b e l l  c  g g e   r k e  \n",
       "24836       c h n  k e  h e v  c r c  f w r e  r e c v e  \n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d4d177b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: clickbait, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "457e4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test_x.apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f64ee279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test_x.apply(lowercasing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "761fc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test_x.apply(remove_punctuations)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4b6047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test1_x.apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b52e9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test1_x.apply(remove_stopwords)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd3e0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test1_x.apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "909107d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test1_x.apply(lemmatzation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36c72f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1_x=test1_x.apply(lambda x: ''.join(i+' ' for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f200f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set (8000, 18248)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_1=tfidf.transform(test1_x)\n",
    "\n",
    "print(\"Shape of test set\",test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9a4d9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_arr=test_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ae0d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 20 predicted labels:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "print('first 20 predicted labels: ',pred.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d082df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [249, 8000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-8968c39c2595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score of the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1272\u001b[0m                          str(average_options))\n\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ykj\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [249, 8000]"
     ]
    }
   ],
   "source": [
    "#Evaluation of Result\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1 score of the model\")\n",
    "print(f1_score(test1_y,pred))\n",
    "print(\"Accuracy of the model\")\n",
    "print(accuracy_score(test1_y,pred))\n",
    "print(\"Accuracy of the model in percentage\")\n",
    "print(accuracy_score(test1_y,pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77854d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
